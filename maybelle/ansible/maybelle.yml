---
- name: Provision Jenkins for Cryptograss
  hosts: all
  connection: local

  vars_files:
    - ../../secrets/vault.yml

  vars:
    jenkins_port: 8080
    docker_users:
      - jenkins
    node_version: "23.6.1"
    domain_name: "maybelle.cryptograss.live"
    github_repo_url: "https://github.com/cryptograss/justinholmes.com" # TODO: make this dynamic?  Certainly it will change with the repo rename.
    jenkins_home: "/var/jenkins_home"
    caddy_config_type: "maybelle"  # Use maybelle-specific Caddyfile template

  pre_tasks:
    - name: Install community.docker collection
      command: ansible-galaxy collection install community.docker
      changed_when: false

  tasks:
    # Note: maybelle-config repo is managed by the chapter scripts on the persistent volume
    # No need to clone it here - we're already running from it

    - name: Install required packages
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - software-properties-common
          - docker.io
          - docker-compose-v2
          - docker-buildx
          - ansible
          - jq
        state: present
        update_cache: yes

    - name: Create Jenkins home directory
      file:
        path: "{{ jenkins_home }}"
        state: directory
        mode: '0755'
        owner: 1000  # jenkins user in container
        group: 1000  # jenkins group in container

    - name: Copy environment file
      copy:
        content: "{{ maybelle_env }}"
        dest: "{{ jenkins_home }}/.env"
        mode: '0600'
        owner: 1000
        group: 1000

    - name: Create Jenkins Docker build directory
      file:
        path: "{{ jenkins_home }}/docker-build"
        state: directory
        mode: '0755'

    - name: Copy Dockerfile and build context
      copy:
        src: "{{ playbook_dir }}/../jenkins-docker/"
        dest: "{{ jenkins_home }}/docker-build/"
        mode: '0644'

    - name: Create blank .bashrc
      file:
        path: "{{ jenkins_home }}/.bashrc"
        state: touch
        mode: '0644'
        owner: 1000
        group: 1000

    - name: Build Jenkins Docker image
      docker_image:
        name: cryptograss-jenkins
        build:
          path: "{{ jenkins_home }}/docker-build"
          pull: yes
        source: build
        force_source: yes

    - name: Create Jenkins Casc Configs directory
      file:
        path: "{{ jenkins_home }}/casc_configs"
        state: directory
        mode: '0755'
        owner: 1000
        group: 1000

    - name: Create Jenkins Docker network
      docker_network:
        name: jenkins-network
        state: present

    - name: Copy Jenkins configuration file
      copy:
        src: "{{ playbook_dir }}/../configs/jenkins.yml"
        dest: "{{ jenkins_home }}/casc_configs/jenkins.yml"
        mode: '0644'
        owner: 1000
        group: 1000
      notify: Restart Jenkins container

    - name: Check if log paths are directories (Docker creates dirs for missing mount sources)
      stat:
        path: "{{ item }}"
      register: log_stats
      loop:
        - /var/log/nfs-backup.log
        - /var/log/nfs-deploy.log
        - /var/log/pickipedia-backup.log
        - /var/log/pickipedia-deploy.log

    - name: Remove log paths if they are directories
      file:
        path: "{{ item.stat.path }}"
        state: absent
      loop: "{{ log_stats.results }}"
      when: item.stat.exists and item.stat.isdir

    - name: Create log files for Jenkins to read
      file:
        path: "{{ item }}"
        state: touch
        mode: '0644'
      loop:
        - /var/log/nfs-backup.log
        - /var/log/nfs-deploy.log
        - /var/log/pickipedia-backup.log
        - /var/log/pickipedia-deploy.log

    - name: Start Jenkins container
      docker_container:
        name: jenkins
        image: cryptograss-jenkins:latest
        restart_policy: unless-stopped
        volumes:
          - "{{ jenkins_home }}:/var/jenkins_home"
          - "/mnt/persist/magenta/backups:/mnt/persist/magenta/backups:ro"
          - "/mnt/persist/pickipedia/backups:/mnt/persist/pickipedia/backups:ro"
          - "/var/log/nfs-backup.log:/var/log/nfs-backup.log:ro"
          - "/var/log/nfs-deploy.log:/var/log/nfs-deploy.log:ro"
          - "/var/log/pickipedia-backup.log:/var/log/pickipedia-backup.log:ro"
          - "/var/log/pickipedia-deploy.log:/var/log/pickipedia-deploy.log:ro"
          # Docker socket removed - Jenkins doesn't need it and it's a security risk
        env_file: "{{ jenkins_home }}/.env"
        env:
          CASC_JENKINS_CONFIG: "/var/jenkins_home/casc_configs/jenkins.yml"
          JENKINS_ADMIN_ID: admin
          JENKINS_ADMIN_PASSWORD: "{{ jenkins_admin_password }}"
          JENKINS_REPORTER_PASSWORD: "{{ jenkins_reporter_password }}"
          GITHUB_TOKEN: "{{ maybelle_github_token }}"
          GITHUB_REPO_URL: "{{ github_repo_url }}"
        ports:
          - "8080:8080"
        networks:
          - name: jenkins-network

    - name: Configure Caddy reverse proxy
      include_role:
        name: caddy

    - name: Create .ssh directory for root
      file:
        path: "/root/.ssh"
        state: directory
        mode: '0700'
        owner: root
        group: root

    - name: Deploy NFS SSH key from vault
      copy:
        content: "{{ nfs_ssh_key | b64decode }}"
        dest: "/root/.ssh/id_ed25519_nfs"
        mode: '0600'
        owner: root
        group: root

    - name: Deploy Jenkins reporter password for deploy scripts
      copy:
        content: "{{ jenkins_reporter_password }}"
        dest: "/root/.jenkins_reporter_password"
        mode: '0600'
        owner: root
        group: root

    - name: Create .ssh directory for jenkins user
      file:
        path: "{{ jenkins_home }}/.ssh"
        state: directory
        mode: '0700'
        owner: 1000
        group: 1000

    - name: Generate backup SSH key for hunter access
      openssh_keypair:
        path: "/var/jenkins_home/.ssh/id_ed25519_backup"
        type: ed25519
        owner: 1000
        group: 1000
        state: present
        comment: "maybelle-backup@hunter"

    - name: Deploy Jenkins GitHub SSH key from vault
      copy:
        content: "{{ jenkins_github_ssh_key | b64decode }}"
        dest: "/var/jenkins_home/.ssh/id_ed25519"
        mode: '0600'
        owner: 1000
        group: 1000

    - name: Deploy hunter root SSH key from vault
      copy:
        content: "{{ hunter_root_ssh_key | b64decode }}"
        dest: "/root/.ssh/id_ed25519_hunter"
        mode: '0600'
        owner: root
        group: root

    - name: Configure SSH for hunter and NFS
      copy:
        dest: "/root/.ssh/config"
        content: |
          Host hunter.cryptograss.live
            IdentityFile ~/.ssh/id_ed25519_hunter
            User root

          Host ssh.nyc1.nearlyfreespeech.net
            IdentityFile ~/.ssh/id_ed25519_nfs
            User jmyles_justinholmescom
        mode: '0600'
        owner: root
        group: root

    - name: Add hunter to known_hosts
      ansible.builtin.shell:
        cmd: "ssh-keyscan -H hunter.cryptograss.live >> /root/.ssh/known_hosts"

    - name: Ensure that known_hosts is present
      ansible.builtin.file:
        path: "~/.ssh/known_hosts"
        state: touch

    - name: Remove stale NFS host key from root known_hosts
      ansible.builtin.shell:
        cmd: "ssh-keygen -f /root/.ssh/known_hosts -R ssh.nyc1.nearlyfreespeech.net 2>/dev/null || true"

    - name: Add current NFS host key to root known_hosts
      ansible.builtin.shell:
        cmd: "ssh-keyscan -H ssh.nyc1.nearlyfreespeech.net >> /root/.ssh/known_hosts 2>/dev/null"
    - name: Add known_hosts entry for github.com
      ansible.builtin.shell:
        cmd: "ssh-keyscan -H github.com >> /var/jenkins_home/.ssh/known_hosts"

    - name: Add hunter to jenkins user known_hosts
      ansible.builtin.shell:
        cmd: "ssh-keyscan -H hunter.cryptograss.live >> /var/jenkins_home/.ssh/known_hosts"

    - name: Fix ownership of jenkins known_hosts
      file:
        path: /var/jenkins_home/.ssh/known_hosts
        owner: 1000
        group: 1000
        mode: '0644'

    - name: Create production deploy script
      copy:
        dest: /usr/local/bin/deploy-to-nfs.sh
        mode: '0750'
        content: |
          #!/bin/bash
          # Deploy production builds to NearlyFreeSpeech
          # Only deploys if Jenkins has marked a successful build

          MARKER_FILE="/var/jenkins_home/www/builds/production/.deploy-ready"
          BUILD_DIR="/var/jenkins_home/www/builds/production"
          LOG_FILE="/var/log/nfs-deploy.log"
          SSH_KEY="/root/.ssh/id_ed25519_nfs"
          NFS_TARGET="jmyles_justinholmescom@ssh.nyc1.nearlyfreespeech.net:"

          # Check if marker exists
          if [ ! -f "$MARKER_FILE" ]; then
              exit 0  # No deploy needed, exit silently
          fi

          # Get build info from marker
          BUILD_INFO=$(cat "$MARKER_FILE")

          echo "$(date): Starting deploy - $BUILD_INFO" >> "$LOG_FILE"

          # Perform the rsync
          if rsync -vah --delete \
              -e "ssh -i $SSH_KEY -o StrictHostKeyChecking=no" \
              "$BUILD_DIR"/* \
              "$NFS_TARGET" >> "$LOG_FILE" 2>&1; then

              # Success - remove marker and log
              rm -f "$MARKER_FILE"
              echo "$(date): Deploy successful" >> "$LOG_FILE"
          else
              echo "$(date): Deploy FAILED" >> "$LOG_FILE"
              exit 1
          fi

    - name: Cronjob to deploy production builds to NFS
      ansible.builtin.cron:
        name: "deploy to nfs"
        job: "/usr/local/bin/deploy-to-nfs.sh"
        minute: "*/2"

    - name: Create PickiPedia production deploy script
      copy:
        dest: /usr/local/bin/deploy-pickipedia-to-nfs.sh
        mode: '0750'
        content: |
          #!/bin/bash
          # Deploy PickiPedia production builds to NearlyFreeSpeech
          # Only deploys if Jenkins has marked a successful build

          MARKER_FILE="/var/jenkins_home/pickipedia_stage/.deploy-ready"
          PAUSE_FILE="/var/jenkins_home/.pickipedia-deploy-paused"
          BUILD_DIR="/var/jenkins_home/pickipedia_stage"
          LOG_FILE="/var/log/pickipedia-deploy.log"
          NFS_TARGET="nfs-pickipedia:"

          # Check if deploys are paused
          if [ -f "$PAUSE_FILE" ]; then
              echo "$(date): Deploy paused - $(cat "$PAUSE_FILE")" >> "$LOG_FILE"
              exit 0
          fi

          # Check if marker exists
          if [ ! -f "$MARKER_FILE" ]; then
              exit 0  # No deploy needed, exit silently
          fi

          # Get build info from marker
          BUILD_INFO=$(cat "$MARKER_FILE")

          echo "$(date): Starting PickiPedia deploy - $BUILD_INFO" >> "$LOG_FILE"

          # Perform the rsync
          # --chmod ensures files are world-readable on NFS
          # Exclude images/ so uploads persist and remain writable
          if rsync -vah --delete \
              --chmod=F644,D755 \
              --exclude='.deploy-ready' \
              --exclude='images/' \
              --exclude='extensions/SemanticMediaWiki/.smw.json' \
              "$BUILD_DIR"/ \
              "$NFS_TARGET" >> "$LOG_FILE" 2>&1; then

              # Success - remove marker and log
              rm -f "$MARKER_FILE"
              echo "$(date): PickiPedia deploy successful" >> "$LOG_FILE"
          else
              echo "$(date): PickiPedia deploy FAILED" >> "$LOG_FILE"
              exit 1
          fi

    - name: Cronjob to deploy PickiPedia production builds to NFS
      ansible.builtin.cron:
        name: "deploy pickipedia to nfs"
        job: "/usr/local/bin/deploy-pickipedia-to-nfs.sh"
        minute: "*/2"

    - name: Remove old rsync cron if exists
      ansible.builtin.cron:
        name: "push sites to prod"
        state: absent

    - name: Create Jenkins job definitions directory
      file:
        path: "{{ jenkins_home }}/casc_configs/jobs"
        state: directory
        mode: '0755'
        owner: 1000
        group: 1000

    - name: Copy Jenkins job definitions
      copy:
        src: "{{ playbook_dir }}/../jobs/"
        dest: "{{ jenkins_home }}/jobs/"
        mode: '0644'
        owner: 1000
        group: 1000
      notify: Restart Jenkins container

    - name: Create Jenkins secrets directory
      file:
        path: "{{ jenkins_home }}/secrets/0"
        state: directory
        mode: '0755'
        owner: 1000
        group: 1000

    - name: Deploy justinholmes.com .env file from vault
      copy:
        content: |
          ALCHEMY_API_KEY={{ ALCHEMY_API_KEY }}
          INFURA_API_KEY={{ INFURA_API_KEY }}
          DISCORD_BOT_TOKEN={{ DISCORD_BOT_TOKEN }}
        dest: "{{ jenkins_home }}/secrets/0/.env"
        mode: '0600'
        owner: 1000
        group: 1000

    - name: Create PickiPedia secrets directory
      file:
        path: "{{ jenkins_home }}/secrets/pickipedia"
        state: directory
        mode: '0755'
        owner: 1000
        group: 1000

    - name: Deploy PickiPedia LocalSettings.local.php from vault
      copy:
        content: |
          <?php
          // Secrets deployed from vault - do not edit manually
          // DB settings point to production NFS MySQL
          $wgSecretKey = "{{ pickipedia_secret_key }}";
          $wgUpgradeKey = "{{ pickipedia_upgrade_key }}";
          $wgDBtype = "mysql";
          $wgDBserver = "{{ pickipedia_db_server }}";
          $wgDBname = "{{ pickipedia_db_name }}";
          $wgDBuser = "{{ pickipedia_db_user }}";
          $wgDBpassword = "{{ pickipedia_db_password }}";
        dest: "{{ jenkins_home }}/secrets/pickipedia/LocalSettings.local.php"
        mode: '0600'
        owner: 1000
        group: 1000

    - name: Create PR builds directory
      file:
        path: "/var/www/builds"
        state: directory
        mode: '0755'
        owner: www-data
        group: www-data

    # Memory Lane services (Django web UI and MCP server)
    # Using persistent volume for all magenta data
    - name: Create magenta directories on persistent volume
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
      loop:
        - /mnt/persist/magenta
        - /mnt/persist/magenta/backups

    - name: Clone or update memory-lane repository
      git:
        repo: https://github.com/jMyles/memory-lane.git
        dest: /mnt/persist/magenta/source
        version: main
        force: yes
        update: yes
        depth: 1
      environment:
        GIT_TERMINAL_PROMPT: "0"

    - name: Create Memory Lane .env file
      copy:
        dest: /mnt/persist/magenta/source/.env
        content: |
          POSTGRES_HOST=magenta-postgres
          POSTGRES_PORT=5432
          POSTGRES_DB=magenta_memory
          POSTGRES_USER=magent
          POSTGRES_PASSWORD={{ memory_lane_postgres_password }}
          DJANGO_ALLOWED_HOSTS=memory-lane.maybelle.cryptograss.live,localhost,10.0.0.2
          DJANGO_DEBUG=False
          INGEST_API_KEY={{ ingest_api_key }}
          SCRUBBER_URL=http://scrubber:8001
        mode: '0600'

    - name: Create docker network for memory lane
      docker_network:
        name: memory-lane-net
        state: present

    # PostgreSQL for Memory Lane
    # Exposed on 10.0.0.2 (Hetzner private network) for dev access from hunter
    - name: Include postgres role
      include_role:
        name: postgres
      vars:
        base_dir: /mnt/persist/magenta
        postgres_password: "{{ memory_lane_postgres_password }}"
        postgres_db: magenta_memory
        postgres_network: memory-lane-net
        postgres_network_external: true
        postgres_bind_address: "10.0.0.2"  # Hetzner private network - allows hunter to connect

    - name: Create Memory Lane docker-compose file
      copy:
        dest: /mnt/persist/magenta/source/docker-compose.maybelle.yml
        content: |
          services:
            memory-lane:
              build:
                context: .
                dockerfile: Dockerfile.services
              container_name: memory-lane
              env_file: .env
              environment:
                - DJANGO_SETTINGS_MODULE=memory_viewer.settings
              ports:
                - "127.0.0.1:3000:3000"
                - "10.0.0.2:3000:3000"
              networks:
                - memory-lane-net
              restart: unless-stopped
              command: gunicorn --bind 0.0.0.0:3000 --workers 2 --access-logfile - memory_viewer.wsgi:application

            mcp-server:
              build:
                context: .
                dockerfile: Dockerfile.services
              container_name: mcp-server
              env_file: .env
              environment:
                - DJANGO_SETTINGS_MODULE=memory_viewer.settings
              ports:
                - "10.0.0.2:8000:8000"
              networks:
                - memory-lane-net
              restart: unless-stopped
              stdin_open: true
              tty: true
              command: python manage.py run_mcp_server_v2 --port 8000

            scrubber:
              build:
                context: ./scrubber
                dockerfile: Dockerfile
              container_name: scrubber
              environment:
                - SECRETS_FILE=/app/secrets/secrets.json
              volumes:
                - scrubber-secrets:/app/secrets
              networks:
                - memory-lane-net
              restart: unless-stopped
              read_only: true
              security_opt:
                - no-new-privileges:true

          volumes:
            scrubber-secrets:

          networks:
            memory-lane-net:
              external: true
              name: memory-lane-net
        mode: '0644'

    - name: Start Memory Lane services
      community.docker.docker_compose_v2:
        project_src: /mnt/persist/magenta/source
        files:
          - docker-compose.maybelle.yml
        build: always
        state: present

    # Inject secrets into scrubber container (from temp file created by chapter-1.sh)
    - name: Check if scrubber secrets temp file exists
      stat:
        path: /tmp/scrubber-secrets.json
      register: scrubber_secrets_file

    - name: Copy secrets into scrubber container
      shell: docker cp /tmp/scrubber-secrets.json scrubber:/app/secrets/secrets.json
      when: scrubber_secrets_file.stat.exists

    - name: Fix secrets file ownership in container
      shell: docker exec -u root scrubber chown scrubber:scrubber /app/secrets/secrets.json
      when: scrubber_secrets_file.stat.exists

    - name: Remove temp secrets file
      file:
        path: /tmp/scrubber-secrets.json
        state: absent
      when: scrubber_secrets_file.stat.exists

    - name: Restart scrubber to load secrets
      shell: docker restart scrubber
      when: scrubber_secrets_file.stat.exists

    - name: Wait for postgres to be ready
      command: docker exec magenta-postgres pg_isready -U magent
      register: pg_ready
      until: pg_ready.rc == 0
      retries: 10
      delay: 2

    - name: Run Django migrations
      command: docker exec memory-lane python manage.py migrate --noinput

    - name: Copy secrets check script into memory-lane container
      shell: docker cp {{ playbook_dir }}/../../scripts/check_db_for_secrets.py memory-lane:/app/check_db_for_secrets.py

    # Restore from backup if database is empty
    # Uses pg_dump custom format (.dump) which avoids psql \restrict issues
    - name: Check if database has data
      shell: docker exec magenta-postgres psql -U magent -d magenta_memory -t -c "SELECT COUNT(*) FROM conversations_message;" 2>/dev/null || echo "0"
      register: db_message_count
      changed_when: false

    - name: List available backups
      shell: |
        ls -lhS /mnt/persist/magenta/backups/magenta_memory_*.dump /mnt/persist/magenta/backups/magenta_memory_*.sql.gz 2>/dev/null | awk '{print NR") "$5" "$9}'
      register: available_backups
      when: db_message_count.stdout | trim | int == 0

    - name: Show available backups
      debug:
        msg: "{{ available_backups.stdout_lines }}"
      when:
        - db_message_count.stdout | trim | int == 0
        - available_backups.stdout | length > 0

    - name: Prompt for backup selection
      pause:
        prompt: "Enter number to restore (1, 2, etc) or 's' to skip"
      register: backup_selection
      when:
        - db_message_count.stdout | trim | int == 0
        - available_backups.stdout | length > 0

    - name: Get selected backup filename
      shell: |
        ls -lhS /mnt/persist/magenta/backups/magenta_memory_*.dump /mnt/persist/magenta/backups/magenta_memory_*.sql.gz 2>/dev/null | awk 'NR=={{ backup_selection.user_input }} {print $9}'
      register: selected_backup
      when:
        - db_message_count.stdout | trim | int == 0
        - backup_selection.user_input | default('s') != 's'
        - backup_selection.user_input | int > 0

    - name: Restore from selected backup
      shell: |
        BACKUP_FILE="{{ selected_backup.stdout }}"
        # Convert host path to container path (/mnt/persist/magenta/backups -> /backups)
        CONTAINER_PATH="/backups/$(basename "$BACKUP_FILE")"
        if [[ "$BACKUP_FILE" == *.dump ]]; then
          # Custom format: use pg_restore with file inside container
          docker exec magenta-postgres pg_restore -U magent -d magenta_memory --no-owner --no-privileges "$CONTAINER_PATH"
        else
          # Legacy plain-text format: use psql (strip \restrict line for pg16+ compatibility)
          gunzip -c "$BACKUP_FILE" | grep -v '^\\restrict ' | docker exec -i magenta-postgres psql -U magent -d magenta_memory
        fi
      when:
        - db_message_count.stdout | trim | int == 0
        - selected_backup.stdout | default('') | length > 0
      register: restore_result

    - name: Report restore status
      debug:
        msg: "Restored database from {{ selected_backup.stdout }}"
      when: restore_result is defined and restore_result.changed | default(false)

    # PostgreSQL backups (backup directory already created above)
    # Uses custom format (-Fc) which is compressed and avoids psql \restrict issues
    - name: Create postgres backup script
      copy:
        dest: /mnt/persist/magenta/backup-postgres.sh
        mode: '0750'
        content: |
          #!/bin/bash
          # Bi-hourly postgres backup
          # Uses pg_dump custom format (-Fc) for reliable cross-server restores
          # Backups named by Ethereum block height for temporal anchoring
          BACKUP_DIR="/mnt/persist/magenta/backups"
          DAILY_DIR="$BACKUP_DIR/daily"

          # Ensure daily directory exists
          mkdir -p "$DAILY_DIR"

          # Get current Ethereum block height
          BLOCK_HEIGHT=$(curl -s https://eth.blockscout.com/api/v2/stats | jq -r .total_blocks)
          if [ -z "$BLOCK_HEIGHT" ] || [ "$BLOCK_HEIGHT" = "null" ]; then
              # Fallback to timestamp if block fetch fails
              BLOCK_HEIGHT="ts_$(date +%Y%m%d_%H%M%S)"
              echo "$(date): WARNING - Could not fetch block height, using timestamp" >> "$BACKUP_DIR/backup.log"
          fi

          BACKUP_FILE="$BACKUP_DIR/magenta_memory_${BLOCK_HEIGHT}.dump"

          # Dump in custom format (already compressed)
          docker exec magenta-postgres pg_dump -Fc -U magent magenta_memory > "$BACKUP_FILE"

          # Log
          echo "$(date): Backup created: $BACKUP_FILE ($(stat -c%s "$BACKUP_FILE") bytes)" >> "$BACKUP_DIR/backup.log"

          # Keep one daily backup (copy the 3am backup to daily folder)
          HOUR=$(date +%H)
          if [ "$HOUR" = "03" ]; then
              cp "$BACKUP_FILE" "$DAILY_DIR/"
              echo "$(date): Daily backup saved to $DAILY_DIR" >> "$BACKUP_DIR/backup.log"
              # Keep daily backups for 30 days
              find "$DAILY_DIR" -name "magenta_memory_*.dump" -mtime +30 -delete
          fi

          # Cleanup bi-hourly backups (keep last 2 days)
          find "$BACKUP_DIR" -maxdepth 1 -name "magenta_memory_*.dump" -mtime +2 -delete
          find "$BACKUP_DIR" -maxdepth 1 -name "magenta_memory_*.sql.gz" -mtime +2 -delete

    - name: Schedule bi-hourly postgres backup
      ansible.builtin.cron:
        name: "postgres bi-hourly backup"
        hour: "*/2"
        minute: "0"
        job: "/mnt/persist/magenta/backup-postgres.sh"

    - name: Remove old daily backup cron if exists
      ansible.builtin.cron:
        name: "postgres daily backup"
        state: absent

    - name: Create offsite backup script
      copy:
        dest: /usr/local/bin/backup-to-nfs.sh
        mode: '0750'
        content: |
          #!/bin/bash
          # Sync daily backups to NearlyFreeSpeech for offsite storage
          LOG_FILE="/var/log/nfs-backup.log"
          BACKUP_DIR="/mnt/persist/magenta/backups/daily"
          NFS_TARGET="jmyles_justinholmescom@ssh.nyc1.nearlyfreespeech.net:/home/private/backups/"

          echo "$(date): Starting offsite backup sync" >> "$LOG_FILE"

          if rsync -avz --delete \
              -e "ssh -i /root/.ssh/id_ed25519_nfs -o StrictHostKeyChecking=no" \
              "$BACKUP_DIR"/ \
              "$NFS_TARGET" >> "$LOG_FILE" 2>&1; then
              echo "$(date): Offsite backup sync successful" >> "$LOG_FILE"
          else
              echo "$(date): Offsite backup sync FAILED" >> "$LOG_FILE"
              exit 1
          fi

    - name: Schedule daily offsite backup sync
      ansible.builtin.cron:
        name: "offsite backup to nfs"
        hour: "4"
        minute: "0"
        job: "/usr/local/bin/backup-to-nfs.sh"

    # PickiPedia backup - pull MySQL dump from NFS for hunter preview
    - name: Create pickipedia backup directory
      file:
        path: /mnt/persist/pickipedia/backups
        state: directory
        mode: '0755'

    - name: Deploy pickipedia backup script
      copy:
        src: "{{ playbook_dir }}/../scripts/backup-pickipedia.sh"
        dest: /usr/local/bin/backup-pickipedia.sh
        mode: '0750'

    - name: Deploy pickipedia MySQL credentials for backup
      copy:
        content: |
          [client]
          user={{ pickipedia_db_user }}
          password={{ pickipedia_db_password }}
        dest: /root/.pickipedia-my.cnf
        mode: '0600'

    - name: Create pickipedia backup log file
      file:
        path: /var/log/pickipedia-backup.log
        state: touch
        mode: '0644'

    - name: Schedule daily pickipedia backup
      ansible.builtin.cron:
        name: "pickipedia backup from nfs"
        hour: "3"
        minute: "30"
        job: "/usr/local/bin/backup-pickipedia.sh"

    - name: Add NFS pickipedia site to SSH config
      blockinfile:
        path: /root/.ssh/config
        marker: "# {mark} PICKIPEDIA NFS"
        block: |
          Host nfs-pickipedia
            HostName ssh.nyc1.nearlyfreespeech.net
            IdentityFile ~/.ssh/id_ed25519_nfs
            User jmyles_pickipedia

    # Security: remove vault password after deploy completes
    # The encrypted vault.yml is in a public repo, so vault password on disk is a risk
    # Re-run chapter-1.sh to restore it if needed for future deploys
    - name: Remove vault password file
      file:
        path: /mnt/persist/.vault-password
        state: absent

    - name: Clean up old scrubber secrets directory if exists
      file:
        path: /mnt/persist/scrubber-secrets
        state: absent

  handlers:
    - name: Restart Jenkins container
      docker_container:
        name: jenkins
        state: started
        restart: yes

  # Handlers are now in roles (caddy role has its own handlers)

