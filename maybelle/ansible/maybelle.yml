---
- name: Provision Jenkins for Cryptograss
  hosts: all
  connection: local

  vars_files:
    - ../../secrets/vault.yml

  vars:
    jenkins_port: 8080
    docker_users:
      - jenkins
    node_version: "23.6.1"
    domain_name: "maybelle.cryptograss.live"
    github_repo_url: "https://github.com/cryptograss/justinholmes.com" # TODO: make this dynamic?  Certainly it will change with the repo rename.
    jenkins_home: "/var/jenkins_home"
    caddy_config_type: "maybelle"  # Use maybelle-specific Caddyfile template

  pre_tasks:
    - name: Install community.docker collection
      command: ansible-galaxy collection install community.docker
      changed_when: false

  tasks:
    # Note: maybelle-config repo is managed by the chapter scripts on the persistent volume
    # No need to clone it here - we're already running from it

    - name: Install required packages
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - software-properties-common
          - docker.io
          - docker-compose-v2
          - docker-buildx
          - ansible
        state: present
        update_cache: yes

    - name: Create Jenkins home directory
      file:
        path: "{{ jenkins_home }}"
        state: directory
        mode: '0755'
        owner: 1000  # jenkins user in container
        group: 1000  # jenkins group in container

    - name: Copy environment file
      copy:
        content: "{{ maybelle_env }}"
        dest: "{{ jenkins_home }}/.env"
        mode: '0600'
        owner: 1000
        group: 1000

    - name: Create Jenkins Docker build directory
      file:
        path: "{{ jenkins_home }}/docker-build"
        state: directory
        mode: '0755'

    - name: Copy Dockerfile and build context
      copy:
        src: "{{ playbook_dir }}/../jenkins-docker/"
        dest: "{{ jenkins_home }}/docker-build/"
        mode: '0644'

    - name: Create blank .bashrc
      file:
        path: "{{ jenkins_home }}/.bashrc"
        state: touch
        mode: '0644'
        owner: 1000
        group: 1000

    - name: Build Jenkins Docker image
      docker_image:
        name: cryptograss-jenkins
        build:
          path: "{{ jenkins_home }}/docker-build"
          pull: yes
        source: build
        force_source: yes

    - name: Create Jenkins Casc Configs directory
      file:
        path: "{{ jenkins_home }}/casc_configs"
        state: directory
        mode: '0755'
        owner: 1000
        group: 1000

    - name: Create Jenkins Docker network
      docker_network:
        name: jenkins-network
        state: present

    - name: Copy Jenkins configuration file
      copy:
        src: "{{ playbook_dir }}/../configs/jenkins.yml"
        dest: "{{ jenkins_home }}/casc_configs/jenkins.yml"
        mode: '0644'
        owner: 1000
        group: 1000
      notify: Restart Jenkins container

    - name: Start Jenkins container
      docker_container:
        name: jenkins
        image: cryptograss-jenkins:latest
        restart_policy: unless-stopped
        volumes:
          - "{{ jenkins_home }}:/var/jenkins_home"
          - /var/run/docker.sock:/var/run/docker.sock
        env_file: "{{ jenkins_home }}/.env"
        env:
          CASC_JENKINS_CONFIG: "/var/jenkins_home/casc_configs/jenkins.yml"
          JENKINS_ADMIN_ID: admin
          JENKINS_ADMIN_PASSWORD: "{{ jenkins_admin_password }}"
          GITHUB_TOKEN: "{{ maybelle_github_token }}"
          GITHUB_REPO_URL: "{{ github_repo_url }}"
        ports:
          - "8080:8080"
        networks:
          - name: jenkins-network

    - name: Configure Caddy reverse proxy
      include_role:
        name: caddy

    - name: Generate SSH key for root
      openssh_keypair:
        path: "~/.ssh/id_ed25519"
        type: ed25519
        state: present

    - name: Create .ssh directory for jenkins user
      file:
        path: "{{ jenkins_home }}/.ssh"
        state: directory
        mode: '0700'
        owner: 1000
        group: 1000

    - name: Generate backup SSH key for hunter access
      openssh_keypair:
        path: "/var/jenkins_home/.ssh/id_ed25519_backup"
        type: ed25519
        owner: 1000
        group: 1000
        state: present
        comment: "maybelle-backup@hunter"

    - name: Deploy Jenkins GitHub SSH key from vault
      copy:
        content: "{{ jenkins_github_ssh_key | b64decode }}"
        dest: "/var/jenkins_home/.ssh/id_ed25519"
        mode: '0600'
        owner: 1000
        group: 1000

    - name: Deploy hunter root SSH key from vault
      copy:
        content: "{{ hunter_root_ssh_key | b64decode }}"
        dest: "/root/.ssh/id_ed25519_hunter"
        mode: '0600'
        owner: root
        group: root

    - name: Add hunter to known_hosts
      ansible.builtin.shell:
        cmd: "ssh-keyscan -H hunter.cryptograss.live >> /root/.ssh/known_hosts"

    - name: Ensure that known_hosts is present
      ansible.builtin.file:
        path: "~/.ssh/known_hosts"
        state: touch

    - name: Add known_hosts entry for nearlyfreespeech.net
      ansible.builtin.known_hosts:
        host: ssh.nyc1.nearlyfreespeech.net
        hash_host: yes
        key: "|1|kXmD+AGFcaF62DEuUeuL+47t/BA=|Ri2jtfePwmmkcsa9BerY+xC+Epw= ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICbXE1f5S3N/flFHUm2i97tzKGJUWzxotY1HHBMIX72h"
        state: present

    - name: Add known_hosts entry for NFS
      ansible.builtin.known_hosts:
        host: gith.nyc1.nearlyfreespeech.net
        hash_host: yes
        key: "|1|kXmD+AGFcaF62DEuUeuL+47t/BA=|Ri2jtfePwmmkcsa9BerY+xC+Epw= ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICbXE1f5S3N/flFHUm2i97tzKGJUWzxotY1HHBMIX72h"
        state: present
    - name: Add known_hosts entry for github.com
      ansible.builtin.shell:
        cmd: "ssh-keyscan -H github.com >> /var/jenkins_home/.ssh/known_hosts"

    - name: Add hunter to jenkins user known_hosts
      ansible.builtin.shell:
        cmd: "ssh-keyscan -H hunter.cryptograss.live >> /var/jenkins_home/.ssh/known_hosts"

    - name: Fix ownership of jenkins known_hosts
      file:
        path: /var/jenkins_home/.ssh/known_hosts
        owner: 1000
        group: 1000
        mode: '0644'

    - name: Cronjob to rsync production builds to web servers
      ansible.builtin.cron:
        name: "push sites to prod"
        job: "rsync -vah --progress --delete /var/jenkins_home/www/builds/production/* jmyles_justinholmescom@ssh.nyc1.nearlyfreespeech.net: >> ~/sites-rsync.log 2>&1"

    - name: Create Jenkins job definitions directory
      file:
        path: "{{ jenkins_home }}/casc_configs/jobs"
        state: directory
        mode: '0755'
        owner: 1000
        group: 1000

    - name: Copy Jenkins job definitions
      copy:
        src: "{{ playbook_dir }}/../jobs/"
        dest: "{{ jenkins_home }}/jobs/"
        mode: '0644'
        owner: 1000
        group: 1000
      notify: Restart Jenkins container

    - name: Create Jenkins secrets directory
      file:
        path: "{{ jenkins_home }}/secrets/0"
        state: directory
        mode: '0755'
        owner: 1000
        group: 1000

    - name: Deploy justinholmes.com .env file from vault
      copy:
        content: |
          ALCHEMY_API_KEY={{ ALCHEMY_API_KEY }}
          INFURA_API_KEY={{ INFURA_API_KEY }}
          DISCORD_BOT_TOKEN={{ DISCORD_BOT_TOKEN }}
        dest: "{{ jenkins_home }}/secrets/0/.env"
        mode: '0600'
        owner: 1000
        group: 1000

    - name: Create PR builds directory
      file:
        path: "/var/www/builds"
        state: directory
        mode: '0755'
        owner: www-data
        group: www-data

    - name: Slurp public SSH key  # TODO: This is only useful as the jenkins user, which doesn't have a key yet.  Better to custody the private key and copy it.  #230
      ansible.builtin.slurp:
        src: ~/.ssh/id_ed25519.pub
      register: ssh_trinket

    - name: Print SSH trinket
      ansible.builtin.debug:
        msg: "{{ ssh_trinket['content'] | b64decode }}"

    # Memory Lane services (Django web UI and MCP server)
    - name: Create magenta directory
      file:
        path: /opt/magenta
        state: directory
        mode: '0755'

    - name: Clone or update magenta repository
      git:
        repo: https://github.com/magent-cryptograss/magenta.git
        dest: /opt/magenta/source
        version: main
        force: yes
        update: yes
        depth: 1
      environment:
        GIT_TERMINAL_PROMPT: "0"

    - name: Create Memory Lane .env file
      copy:
        dest: /opt/magenta/source/.env
        content: |
          POSTGRES_HOST=magenta-postgres
          POSTGRES_PORT=5432
          POSTGRES_DB=magenta_memory
          POSTGRES_USER=magent
          POSTGRES_PASSWORD={{ memory_lane_postgres_password }}
          DJANGO_ALLOWED_HOSTS=memory-lane.maybelle.cryptograss.live,localhost
        mode: '0600'

    - name: Create docker network for memory lane
      docker_network:
        name: memory-lane-net
        state: present

    # PostgreSQL for Memory Lane
    - name: Include postgres role
      include_role:
        name: postgres
      vars:
        base_dir: /opt/magenta
        postgres_password: "{{ memory_lane_postgres_password }}"
        postgres_db: magenta_memory
        postgres_network: memory-lane-net
        postgres_network_external: true

    - name: Create Memory Lane docker-compose file
      copy:
        dest: /opt/magenta/source/docker-compose.maybelle.yml
        content: |
          services:
            memory-lane:
              build:
                context: .
                dockerfile: Dockerfile.services
              container_name: memory-lane
              env_file: .env
              environment:
                - DJANGO_SETTINGS_MODULE=memory_viewer.settings
              ports:
                - "127.0.0.1:3000:3000"
              networks:
                - memory-lane-net
              restart: unless-stopped
              command: gunicorn --bind 0.0.0.0:3000 --workers 2 --access-logfile - memory_viewer.wsgi:application

            mcp-server:
              build:
                context: .
                dockerfile: Dockerfile.services
              container_name: mcp-server
              env_file: .env
              environment:
                - DJANGO_SETTINGS_MODULE=memory_viewer.settings
              ports:
                - "10.0.0.2:8000:8000"
              networks:
                - memory-lane-net
              restart: unless-stopped
              stdin_open: true
              tty: true
              command: python manage.py run_mcp_server_v2 --port 8000

          networks:
            memory-lane-net:
              external: true
              name: memory-lane-net
        mode: '0644'

    - name: Start Memory Lane services
      community.docker.docker_compose_v2:
        project_src: /opt/magenta/source
        files:
          - docker-compose.maybelle.yml
        build: always
        state: present

    # PostgreSQL backups
    - name: Create postgres backup directory
      file:
        path: /opt/magenta/backups
        state: directory
        mode: '0750'

    - name: Create postgres backup script
      copy:
        dest: /opt/magenta/backup-postgres.sh
        mode: '0750'
        content: |
          #!/bin/bash
          # Daily postgres backup with 7-day retention
          BACKUP_DIR="/opt/magenta/backups"
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BACKUP_FILE="$BACKUP_DIR/magenta_memory_$TIMESTAMP.sql.gz"

          # Dump and compress
          docker exec magenta-postgres pg_dump -U magent magenta_memory | gzip > "$BACKUP_FILE"

          # Log
          echo "$(date): Backup created: $BACKUP_FILE ($(stat -c%s "$BACKUP_FILE") bytes)" >> "$BACKUP_DIR/backup.log"

          # Cleanup old backups (keep last 7 days)
          find "$BACKUP_DIR" -name "magenta_memory_*.sql.gz" -mtime +7 -delete

    - name: Schedule daily postgres backup
      ansible.builtin.cron:
        name: "postgres daily backup"
        hour: "3"
        minute: "0"
        job: "/opt/magenta/backup-postgres.sh"

  handlers:
    - name: Restart Jenkins container
      docker_container:
        name: jenkins
        state: started
        restart: yes

  # Handlers are now in roles (caddy role has its own handlers)

